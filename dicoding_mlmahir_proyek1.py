# -*- coding: utf-8 -*-
"""Dicoding_MLMahir_Proyek1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bIcf3lX3zg72QDjSAtzkqIFldv8XPpzI

###1. Import Library###
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier

"""###2. Mempersiapkan data set###"""

data = pd.read_csv("healthcare-dataset-stroke-data.csv")
data.head()

data.drop(columns='id', inplace=True)
data.info()

data.describe()

"""###3. Data Preprocessing###"""

data.isna().sum()

data.shape

data.dropna(how='any', inplace=True)

data.isna().sum()

numeric_columns = ['age', 'bmi', 'avg_glucose_level']
categorical_columns = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke']

"""Visualisasi dan Plot"""

i = 0
fig, ax = plt.subplots(3, 3, figsize=(15, 8))
plt.subplots_adjust(hspace=0.5)

for num_col in numeric_columns:
    # Plot KDE
    sns.kdeplot(x=num_col, hue='stroke', data=data, multiple='stack', ax=ax[i, 0])
    ax[i, 0].set_title("KDE Plot")

    # Plot Boxplot
    sns.boxplot(x=num_col, data=data, ax=ax[i, 1])
    ax[i, 1].set_title("Boxplot")

    # Plot Scatterplot
    sns.scatterplot(x=num_col, y='stroke', data=data, ax=ax[i, 2])
    ax[i, 2].set_title("Scatterplot")

    i += 1

plt.show()

i = 0
while i < 8:
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Plot for the left axes
    ax_left = axes[0]
    ax_left.set_title(categorical_columns[i], size=20, weight='bold', color='navy')
    sns.countplot(x=categorical_columns[i], data=data, ax=ax_left)
    ax_left.bar_label(ax_left.containers[0])
    ax_left.tick_params(axis='x', rotation=300)
    i += 1

    # Plot for the right axes
    ax_right = axes[1]
    ax_right.set_title(categorical_columns[i], size=20, weight='bold', color='navy')
    sns.countplot(x=categorical_columns[i], data=data, ax=ax_right)
    ax_right.bar_label(ax_right.containers[0])
    ax_right.tick_params(axis='x', rotation=300)
    i += 1

    plt.show()

x = data['stroke'].value_counts()

explode = [0, 0.15]
labels = ['Stroke=0', 'Stroke=1']
fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(aspect="equal"))

ax.pie(x, explode=explode, autopct='%1.1f%%', labels=labels, textprops=dict(color="w", weight='bold', size=15))
ax.legend()
plt.show()

"""Mentransformasi data"""

columns_temp = ['gender', 'ever_married', 'work_type', 'smoking_status', 'Residence_type']

for col in columns_temp :
    print('column :', col)
    for index, unique in enumerate(data[col].unique()) :
        print(unique, ':', index)
    print('_'*45)

#gender
data_2 = data.replace(
    {'gender' : {'Male' : 0, 'Female' : 1, 'Other' : 2}}
)

#ever_married
data_2 =  data_2.replace(
    {'ever_married' : {'Yes' : 0, 'No' : 1}}
)

#work_type
data_2 =  data_2.replace(
    {'work_type' : {'Private' : 0, 'Self-employed' : 1, 'Govt_job' : 2, 'children' : 3, 'Never_worked' : 4}}
)

#smoking_status
data_2 =  data_2.replace(
    {'smoking_status' : {'formerly smoked' : 0, 'never smoked' : 1, 'smokes' : 2, 'Unknown' : 3}}
)

#Residence_type
data_2 =  data_2.replace(
    {'Residence_type' : {'Urban' : 0, 'Rural' : 1}}
)

data_2 = data_2[data_2['gender'] != 2]

data_2.head()

"""Normalisasi Data"""

X_temp = data_2.drop(columns='stroke')
y = data_2.stroke

scaler = MinMaxScaler().fit_transform(X_temp)
X = pd.DataFrame(scaler, columns=X_temp.columns)
X.describe()

"""##4. Modelling##"""

def plot_confusion_matrix(y_test, y_prediction):
    cm = metrics.confusion_matrix(y_test, y_prediction)
    ax = plt.subplot()
    ax = sns.heatmap(cm, annot=True, fmt='', cmap="Greens")
    ax.set_xlabel('Prediced labels')
    ax.set_ylabel('True labels')
    ax.set_title('Confusion Matrix')
    ax.xaxis.set_ticklabels(['Dont Had Stroke', 'Had Stroke'])
    ax.yaxis.set_ticklabels(['Dont Had Stroke', 'Had Stroke'])
    plt.show()

# Splite X, y to train & test dataset.
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)

"""RandomForestClassifier"""

#parameters
parameters = {
    'n_estimators' : [50, 100, 250, 500],
    'criterion' : ['gini', 'entropy', 'log_loss'],
    'max_features' : ['sqrt', 'log2']
}

rf = RandomForestClassifier(n_jobs=-1)
rf_cv = GridSearchCV(estimator=rf, cv=10, param_grid=parameters).fit(X_train, y_train)

print('Tuned hyper parameters : ', rf_cv.best_params_)
print('accuracy : ', rf_cv.best_score_)

# calculate time befor run algorithm
t1 = datetime.now()
# Model :
rf = RandomForestClassifier(**rf_cv.best_params_).fit(X_train, y_train)
# calculate time after run algorithm
t2 = datetime.now()

#
y_pred_rf = rf.predict(X_test)

rf_score = round(rf.score(X_test, y_test), 3)
print('RandomForestClassifier score : ', rf_score)

delta = t2-t1
delta_rf = round(delta.total_seconds(), 3)
print('RandomForestClassifier takes : ', delta_rf, 'Seconds')

plot_confusion_matrix(y_test, y_pred_rf)

cr = metrics.classification_report(y_test, y_pred_rf)
print(cr)

"""DecisionTreeClassifier"""

#parameters
parameters = {
    'criterion' : ['gini', 'entropy', 'log_loss'],
    'splitter' : ['best', 'random'],
    'max_depth' : list(np.arange(4, 30, 1))
        }



tree = DecisionTreeClassifier()
tree_cv = GridSearchCV(estimator=tree, cv=10, param_grid=parameters).fit(X_train, y_train)



print('Tuned hyper parameters : ', tree_cv.best_params_)
print('accuracy : ', tree_cv.best_score_)

# Calculate time befor run algorithm :
t1 = datetime.now()
# Model :
tree = DecisionTreeClassifier(**tree_cv.best_params_).fit(X_train, y_train)
# Calculate time after run algorithm :
t2 = datetime.now()

y_pred_tree = tree.predict(X_test)

tree_score = round(tree.score(X_test, y_test), 3)
print('DecisionTreeClassifier Score : ', tree_score)

delta = t2-t1
delta_tree = round(delta.total_seconds(), 3)
print('DecisionTreeClassifier takes : ', delta_tree, 'Seconds')

plot_confusion_matrix(y_test, y_pred_tree)

cr = metrics.classification_report(y_test, y_pred_tree)
print(cr)

"""Hasil Akhir"""

result = pd.DataFrame({
    'Algorithm' : ['RandomForestClassifier', 'DecisionTreeClassifier'],
    'Score' : [rf_score, tree_score,],
    'Delta_t' : [delta_rf, delta_tree,]
})

result

fig, ax = plt.subplots(1, 2, figsize=(15, 5))

sns.barplot(x='Algorithm', y='Score', data=result, ax=ax[0])
ax[0].bar_label(ax[0].containers[0], fmt='%.3f')
ax[0].set_xticklabels(labels=result.Algorithm, rotation=300)

sns.barplot(x='Algorithm', y='Delta_t', data=result, ax=ax[1])
ax[1].bar_label(ax[1].containers[0], fmt='%.3f')
ax[1].set_xticklabels(labels=result.Algorithm, rotation=300)
plt.show()

"""##5. Kesimpulan##

Kedua model, RandomForestClassifier dan DecisionTreeClassifier, memiliki skor akurasi yang sama, yaitu 0.96. Namun, model DecisionTreeClassifier memiliki waktu eksekusi yang jauh lebih cepat dibandingkan RandomForestClassifier. Dengan Delta_t hanya 0.008 detik, model DecisionTreeClassifier mungkin lebih efisien dalam penggunaan sumber daya komputasi.
"""